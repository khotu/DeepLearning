{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "Linear regression is probably the first machine learning algorithm that most people learn when starting off in this field. Learning this model is a great way to get introduced to the idea of supervised learning.\n",
    "\n",
    "We have some (input, output) pairs which we denote as $ (x_i, y_i) $ and we have $n$ of these, so $i \\in [1...n]$. We want to learn a function $f: x \\rightarrow{} y$ that maps inputs to outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = load_boston(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = targets.reshape((targets.shape[0],1))\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(data, targets, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input and output\n",
    "Our goal is to learn a function  $ f: x \\rightarrow{} y$ that maps information about the house, With Linear Regression our $f$ is just a Linear Combination of houses independent fetures.\n",
    "\n",
    "$$ f(X) = (w_1*X_1) + (w_2*X_2) + ..... (w_{13}*X_{13}) + bias = \\sum_{i_1}^{13} (w_i * X_i) +bias$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(None, 13), dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(None, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "x = tf.compat.v1.placeholder(dtype=tf.float32, shape=(None,train_x.shape[1]))\n",
    "print(x)\n",
    "y = tf.compat.v1.placeholder(dtype=tf.float32, shape=(None,train_y.shape[1]))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Random Weight and bias\n",
    "\n",
    "Next, we will initialize the random weights and bias term, As a  result our model won't be able to predict the house price very well.Learning is the process of adjusting these parameters so that our model's accuracy increases. In order to do this, we need to mathematically quantify how \"bad\" our model is currently. We can do this by calculating how off each prediction is from the actual value: \n",
    "\n",
    "$$ L = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - f(x_i))^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random.normal(shape = (13,1)))\n",
    "b = tf.Variable(tf.random.normal(shape = (1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.matmul(x, w)+ b\n",
    "error  = tf.reduce_mean(tf.square(y-y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "If we take derivaties of this loss function respective to each weight, then we will learn how much to adjust these weight $w$ to optimize the error / Loss function. This Algorithm is Known as Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "optmze = optimizer.minimize(loss=error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 7000\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "sess = tf.compat.v1.InteractiveSession()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  81.330574\n",
      "loss :  54.52715\n",
      "loss :  52.059166\n",
      "loss :  50.418705\n",
      "loss :  49.040672\n",
      "loss :  47.803352\n",
      "loss :  46.666233\n",
      "loss :  45.611416\n",
      "loss :  44.62909\n",
      "loss :  43.712566\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    sess.run(optmze, feed_dict={x:train_x, y:train_y})\n",
    "    if i%700 ==0 :\n",
    "        print(\"loss : \", sess.run(error, feed_dict={x:train_x, y:train_y} ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "prdiction = sess.run(y_pred, feed_dict={x:test_x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House prices are variated 5.242436644610237 thousand dollars\n"
     ]
    }
   ],
   "source": [
    "print(f\"House prices are variated {mean_absolute_error(test_y, prdiction)} thousand dollars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
