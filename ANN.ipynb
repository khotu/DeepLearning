{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "ANN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khotu/DeepLearning/blob/master/ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6NzUovVk_dz",
        "colab_type": "code",
        "outputId": "4ad38540-b8ab-43f5-a651-9f8aef3ee1e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import pandas as pd\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import io\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C426if63lGVj",
        "colab_type": "code",
        "outputId": "3a4c4446-6668-4e61-8332-f1c9c44c3ac8",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fd0b0d29-c131-48be-9592-bb550a3699d1\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-fd0b0d29-c131-48be-9592-bb550a3699d1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Churn_Modelling.csv to Churn_Modelling.csv\n",
            "User uploaded file \"Churn_Modelling.csv\" with length 684858 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcng6TH1lHFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(io.StringIO(uploaded['Churn_Modelling.csv'].decode('utf-8')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNtAZoy_paK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df = pd.read_csv('/content/Churn_Modelling.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfuZuRAZk_eh",
        "colab_type": "code",
        "outputId": "a17744d3-ec47-4a8d-c639-131fad475f57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxmobEr3k_e0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_copy = df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT1ZwFiqk_e_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_copy.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7IMUzSJk_fK",
        "colab_type": "code",
        "outputId": "5313860f-bde0-4490-e83e-aa74d42b87be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_copy.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore Geography  Gender  ...  IsActiveMember  EstimatedSalary  Exited\n",
              "0          619    France  Female  ...               1        101348.88       1\n",
              "1          608     Spain  Female  ...               1        112542.58       0\n",
              "2          502    France  Female  ...               0        113931.57       1\n",
              "3          699    France  Female  ...               0         93826.63       0\n",
              "4          850     Spain  Female  ...               1         79084.10       0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DVOT49EmKFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1ChayDnmPo8",
        "colab_type": "code",
        "outputId": "5edf8379-042a-4e62-f189-473be4e6f054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "sns.countplot(x='Exited', data= df)\n",
        "exited, not_exited = df.Exited.value_counts()\n",
        "print(\"Exited :\", exited)\n",
        "print(\"Not Exited : \", not_exited)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exited : 7963\n",
            "Not Exited :  2037\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFzrbOyJk_fW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "geo_dumm = pd.get_dummies(df_copy.Geography, drop_first = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHd9WtVvk_fg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_dumm = pd.get_dummies(df_copy.Gender, drop_first = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R9SqnMWk_ft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_copy.drop(['Geography','Gender'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yEt6n2_k_f2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_copy = pd.concat([df_copy, gen_dumm, geo_dumm], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh8WGmVPk_gD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df_copy.drop('Exited', axis=1)\n",
        "y = df_copy['Exited']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGc0m6SSk_gN",
        "colab_type": "code",
        "outputId": "024db751-4f23-4479-8b57-cf94580505d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_x, test_x, train_y, test_y = train_test_split(x,y, test_size = 0.2, random_state = 0)\n",
        "train_x.shape\n",
        "train_y.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHS-X3fYk_gW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ss = StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdWyT4uyk_gg",
        "colab_type": "code",
        "outputId": "4eacc372-2820-4726-89ec-ca25af3c6bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_x = ss.fit_transform(train_x)\n",
        "test_x = ss.transform(test_x)\n",
        "train_x.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKMczECZk_gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlbqZEZTk_g1",
        "colab_type": "code",
        "outputId": "18ed7d84-5b85-4214-ab6c-5ef4abe1db42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "classifier = Sequential()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA4u2_pek_hB",
        "colab_type": "code",
        "outputId": "2a63541c-26fe-4493-863b-aae7239087e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "classifier.add(Dense(units=8, input_dim =11 ,  activation='relu', kernel_initializer= 'uniform', use_bias=True ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vNXSF0Tk_hK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.add(Dense(units=6, activation='relu', kernel_initializer= 'uniform', use_bias=True))\n",
        "classifier.add(Dense(units=6, activation='relu', kernel_initializer= 'uniform',use_bias=True ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC32PKhRk_hT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.add(Dense(units=1, activation='sigmoid', kernel_initializer = 'uniform',use_bias=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap_fn_d2k_hc",
        "colab_type": "code",
        "outputId": "62851bf7-3ba0-4d7e-aa76-b30f6ebc58df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "classifier.compile(optimizer='adam', metrics=['accuracy'], loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3za81hYwk_hl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.fit(train_x, train_y, batch_size=100, epochs=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9IjyR0Gk_hx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred =classifier.predict(test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDvW2OuCk_h5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = (y_pred > 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJs2FfFck_iB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PozYgwDk_iJ",
        "colab_type": "code",
        "outputId": "6aaea687-e00a-4f5d-f36c-d5a494c082e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy_score(test_y, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8595"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfkzrfDWk_iU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R7mS_Fh32Ea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Evaluating  model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsv0ampS38Gh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbR1Ayye5m5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def built_classifier(optimizer= 'adam', dropout_rate = 0.1):\n",
        "  classifier = Sequential()\n",
        "  classifier.add(Dense(units=8, input_dim =11 ,  activation='relu', kernel_initializer= 'uniform', use_bias=True ))\n",
        "  classifier.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "  classifier.add(Dense(units=6, activation='relu', kernel_initializer= 'uniform', use_bias=True))\n",
        "  classifier.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "  classifier.add(Dense(units=6, activation='relu', kernel_initializer= 'uniform', use_bias=True ))\n",
        "  classifier.add(Dense(units=1, activation='sigmoid', kernel_initializer = 'uniform', use_bias=True))\n",
        "  classifier.compile(optimizer=optimizer, metrics=['accuracy'], loss='binary_crossentropy')\n",
        "  return classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPK42ogo-Ixd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = KerasClassifier(build_fn=built_classifier,batch_size=100, epochs=200, )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljv1Aiyi-jxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy = cross_val_score(estimator=classifier, X = train_x, y = train_y, cv = 10, scoring='accuracy', n_jobs=-1, )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEE6ltXL_Pn6",
        "colab_type": "code",
        "outputId": "8330b0a1-23ac-49ae-c6e6-f4e1d5cbc806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy.mean()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8355"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-V4TiF6BJJn",
        "colab_type": "code",
        "outputId": "50b4a8b1-196d-4cc7-dc14-af7511767758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy.std()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.013028814220795389"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp4otlMzBK6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parammeter = {'optimizer': ['RMSprop', 'adam'],\n",
        "              'dropout_rate' : [0.05, 0.2]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfFU1bNoCFCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_search = GridSearchCV( estimator=classifier, param_grid=parammeter, cv = 5, scoring='accuracy', n_jobs=-1, )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lsuIoOd3q_w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d91e5477-01a5-433e-8fed-b167c74f8300"
      },
      "source": [
        "grid_search.fit(X=train_x, y=train_y)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/200\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "8000/8000 [==============================] - 1s 169us/step - loss: 0.6740 - acc: 0.7900\n",
            "Epoch 2/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.6078 - acc: 0.7960\n",
            "Epoch 3/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.5030 - acc: 0.7960\n",
            "Epoch 4/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4520 - acc: 0.7960\n",
            "Epoch 5/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4442 - acc: 0.7960\n",
            "Epoch 6/200\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4402 - acc: 0.7960\n",
            "Epoch 7/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4368 - acc: 0.7960\n",
            "Epoch 8/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4341 - acc: 0.7960\n",
            "Epoch 9/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4328 - acc: 0.7960\n",
            "Epoch 10/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4308 - acc: 0.7960\n",
            "Epoch 11/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4299 - acc: 0.7960\n",
            "Epoch 12/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4271 - acc: 0.7960\n",
            "Epoch 13/200\n",
            "8000/8000 [==============================] - 0s 47us/step - loss: 0.4269 - acc: 0.7960\n",
            "Epoch 14/200\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4268 - acc: 0.7960\n",
            "Epoch 15/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4230 - acc: 0.7960\n",
            "Epoch 16/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4241 - acc: 0.7999\n",
            "Epoch 17/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4222 - acc: 0.8171\n",
            "Epoch 18/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4230 - acc: 0.8180\n",
            "Epoch 19/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4205 - acc: 0.8195\n",
            "Epoch 20/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4196 - acc: 0.8217\n",
            "Epoch 21/200\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4195 - acc: 0.8221\n",
            "Epoch 22/200\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4197 - acc: 0.8236\n",
            "Epoch 23/200\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4207 - acc: 0.8227\n",
            "Epoch 24/200\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4196 - acc: 0.8270\n",
            "Epoch 25/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4183 - acc: 0.8266\n",
            "Epoch 26/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4173 - acc: 0.8271\n",
            "Epoch 27/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4183 - acc: 0.8270\n",
            "Epoch 28/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4155 - acc: 0.8261\n",
            "Epoch 29/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4165 - acc: 0.8282\n",
            "Epoch 30/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4172 - acc: 0.8284\n",
            "Epoch 31/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4182 - acc: 0.8291\n",
            "Epoch 32/200\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4168 - acc: 0.8305\n",
            "Epoch 33/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4168 - acc: 0.8294\n",
            "Epoch 34/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4155 - acc: 0.8286\n",
            "Epoch 35/200\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4135 - acc: 0.8311\n",
            "Epoch 36/200\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4150 - acc: 0.8311\n",
            "Epoch 37/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4152 - acc: 0.8303\n",
            "Epoch 38/200\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4138 - acc: 0.8287\n",
            "Epoch 39/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4143 - acc: 0.8321\n",
            "Epoch 40/200\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4153 - acc: 0.8304\n",
            "Epoch 41/200\n",
            "8000/8000 [==============================] - 0s 44us/step - loss: 0.4145 - acc: 0.8330\n",
            "Epoch 42/200\n",
            "8000/8000 [==============================] - 0s 43us/step - loss: 0.4124 - acc: 0.8319\n",
            "Epoch 43/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4134 - acc: 0.8316\n",
            "Epoch 44/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4116 - acc: 0.8319\n",
            "Epoch 45/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4144 - acc: 0.8310\n",
            "Epoch 46/200\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4136 - acc: 0.8311\n",
            "Epoch 47/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4137 - acc: 0.8319\n",
            "Epoch 48/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4124 - acc: 0.8339\n",
            "Epoch 49/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4131 - acc: 0.8332\n",
            "Epoch 50/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4120 - acc: 0.8316\n",
            "Epoch 51/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4121 - acc: 0.8314\n",
            "Epoch 52/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4126 - acc: 0.8330\n",
            "Epoch 53/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4134 - acc: 0.8350\n",
            "Epoch 54/200\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4144 - acc: 0.8330\n",
            "Epoch 55/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4142 - acc: 0.8311\n",
            "Epoch 56/200\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4133 - acc: 0.8338\n",
            "Epoch 57/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4112 - acc: 0.8335\n",
            "Epoch 58/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4133 - acc: 0.8331\n",
            "Epoch 59/200\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4124 - acc: 0.8322\n",
            "Epoch 60/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4126 - acc: 0.8300\n",
            "Epoch 61/200\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4112 - acc: 0.8323\n",
            "Epoch 62/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4118 - acc: 0.8342\n",
            "Epoch 63/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4105 - acc: 0.8323\n",
            "Epoch 64/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4115 - acc: 0.8310\n",
            "Epoch 65/200\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4121 - acc: 0.8331\n",
            "Epoch 66/200\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4119 - acc: 0.8346\n",
            "Epoch 67/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4110 - acc: 0.8344\n",
            "Epoch 68/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4116 - acc: 0.8326\n",
            "Epoch 69/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4112 - acc: 0.8346\n",
            "Epoch 70/200\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4115 - acc: 0.8337\n",
            "Epoch 71/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4127 - acc: 0.8345\n",
            "Epoch 72/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4111 - acc: 0.8337\n",
            "Epoch 73/200\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4132 - acc: 0.8320\n",
            "Epoch 74/200\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4110 - acc: 0.8349\n",
            "Epoch 75/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4133 - acc: 0.8340\n",
            "Epoch 76/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4108 - acc: 0.8345\n",
            "Epoch 77/200\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4126 - acc: 0.8347\n",
            "Epoch 78/200\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4130 - acc: 0.8319\n",
            "Epoch 79/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4103 - acc: 0.8320\n",
            "Epoch 80/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4090 - acc: 0.8326\n",
            "Epoch 81/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4105 - acc: 0.8315\n",
            "Epoch 82/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4100 - acc: 0.8312\n",
            "Epoch 83/200\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4120 - acc: 0.8296\n",
            "Epoch 84/200\n",
            "8000/8000 [==============================] - 0s 43us/step - loss: 0.4123 - acc: 0.8341\n",
            "Epoch 85/200\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4126 - acc: 0.8328\n",
            "Epoch 86/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4126 - acc: 0.8325\n",
            "Epoch 87/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4119 - acc: 0.8362\n",
            "Epoch 88/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4125 - acc: 0.8317\n",
            "Epoch 89/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4117 - acc: 0.8324\n",
            "Epoch 90/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4144 - acc: 0.8325\n",
            "Epoch 91/200\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4124 - acc: 0.8327\n",
            "Epoch 92/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4108 - acc: 0.8337\n",
            "Epoch 93/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4124 - acc: 0.8316\n",
            "Epoch 94/200\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4101 - acc: 0.8325\n",
            "Epoch 95/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4114 - acc: 0.8336\n",
            "Epoch 96/200\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4122 - acc: 0.8322\n",
            "Epoch 97/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4105 - acc: 0.8315\n",
            "Epoch 98/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4105 - acc: 0.8353\n",
            "Epoch 99/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4118 - acc: 0.8342\n",
            "Epoch 100/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4089 - acc: 0.8329\n",
            "Epoch 101/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4130 - acc: 0.8319\n",
            "Epoch 102/200\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4105 - acc: 0.8327\n",
            "Epoch 103/200\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4120 - acc: 0.8317\n",
            "Epoch 104/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4145 - acc: 0.8319\n",
            "Epoch 105/200\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4119 - acc: 0.8324\n",
            "Epoch 106/200\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4075 - acc: 0.8340\n",
            "Epoch 107/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4105 - acc: 0.8320\n",
            "Epoch 108/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4112 - acc: 0.8331\n",
            "Epoch 109/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4125 - acc: 0.8326\n",
            "Epoch 110/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4137 - acc: 0.8320\n",
            "Epoch 111/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4116 - acc: 0.8337\n",
            "Epoch 112/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4105 - acc: 0.8325\n",
            "Epoch 113/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4115 - acc: 0.8342\n",
            "Epoch 114/200\n",
            "8000/8000 [==============================] - 0s 45us/step - loss: 0.4126 - acc: 0.8313\n",
            "Epoch 115/200\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4092 - acc: 0.8301\n",
            "Epoch 116/200\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4099 - acc: 0.8351\n",
            "Epoch 117/200\n",
            "8000/8000 [==============================] - 0s 44us/step - loss: 0.4118 - acc: 0.8324\n",
            "Epoch 118/200\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4099 - acc: 0.8322\n",
            "Epoch 119/200\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4115 - acc: 0.8350\n",
            "Epoch 120/200\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4100 - acc: 0.8320\n",
            "Epoch 121/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4073 - acc: 0.8350\n",
            "Epoch 122/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4093 - acc: 0.8340\n",
            "Epoch 123/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4111 - acc: 0.8300\n",
            "Epoch 124/200\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4122 - acc: 0.8322\n",
            "Epoch 125/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4104 - acc: 0.8335\n",
            "Epoch 126/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4112 - acc: 0.8334\n",
            "Epoch 127/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4108 - acc: 0.8334\n",
            "Epoch 128/200\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4102 - acc: 0.8341\n",
            "Epoch 129/200\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4088 - acc: 0.8331\n",
            "Epoch 130/200\n",
            "8000/8000 [==============================] - 0s 44us/step - loss: 0.4099 - acc: 0.8339\n",
            "Epoch 131/200\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4108 - acc: 0.8344\n",
            "Epoch 132/200\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4106 - acc: 0.8327\n",
            "Epoch 133/200\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4105 - acc: 0.8332\n",
            "Epoch 134/200\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4082 - acc: 0.8316\n",
            "Epoch 135/200\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4090 - acc: 0.8324\n",
            "Epoch 136/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4104 - acc: 0.8349\n",
            "Epoch 137/200\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4136 - acc: 0.8312\n",
            "Epoch 138/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4119 - acc: 0.8327\n",
            "Epoch 139/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4086 - acc: 0.8326\n",
            "Epoch 140/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4111 - acc: 0.8332\n",
            "Epoch 141/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4097 - acc: 0.8337\n",
            "Epoch 142/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4080 - acc: 0.8344\n",
            "Epoch 143/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4111 - acc: 0.8332\n",
            "Epoch 144/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4114 - acc: 0.8327\n",
            "Epoch 145/200\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4108 - acc: 0.8320\n",
            "Epoch 146/200\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4098 - acc: 0.8312\n",
            "Epoch 147/200\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4113 - acc: 0.8319\n",
            "Epoch 148/200\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4098 - acc: 0.8324\n",
            "Epoch 149/200\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4105 - acc: 0.8319\n",
            "Epoch 150/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4108 - acc: 0.8348\n",
            "Epoch 151/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4097 - acc: 0.8319\n",
            "Epoch 152/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4089 - acc: 0.8326\n",
            "Epoch 153/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4104 - acc: 0.8334\n",
            "Epoch 154/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4111 - acc: 0.8314\n",
            "Epoch 155/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4090 - acc: 0.8329\n",
            "Epoch 156/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4103 - acc: 0.8335\n",
            "Epoch 157/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4120 - acc: 0.8315\n",
            "Epoch 158/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4115 - acc: 0.8328\n",
            "Epoch 159/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4107 - acc: 0.8332\n",
            "Epoch 160/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4103 - acc: 0.8329\n",
            "Epoch 161/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4077 - acc: 0.8361\n",
            "Epoch 162/200\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4089 - acc: 0.8325\n",
            "Epoch 163/200\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4104 - acc: 0.8329\n",
            "Epoch 164/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4083 - acc: 0.8323\n",
            "Epoch 165/200\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4116 - acc: 0.8329\n",
            "Epoch 166/200\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4106 - acc: 0.8342\n",
            "Epoch 167/200\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4121 - acc: 0.8315\n",
            "Epoch 168/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4091 - acc: 0.8299\n",
            "Epoch 169/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4080 - acc: 0.8348\n",
            "Epoch 170/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4110 - acc: 0.8327\n",
            "Epoch 171/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4105 - acc: 0.8336\n",
            "Epoch 172/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4109 - acc: 0.8341\n",
            "Epoch 173/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4110 - acc: 0.8329\n",
            "Epoch 174/200\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4110 - acc: 0.8335\n",
            "Epoch 175/200\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4082 - acc: 0.8317\n",
            "Epoch 176/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4099 - acc: 0.8334\n",
            "Epoch 177/200\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4107 - acc: 0.8334\n",
            "Epoch 178/200\n",
            "8000/8000 [==============================] - 0s 44us/step - loss: 0.4098 - acc: 0.8331\n",
            "Epoch 179/200\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4102 - acc: 0.8338\n",
            "Epoch 180/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4115 - acc: 0.8314\n",
            "Epoch 181/200\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4104 - acc: 0.8328\n",
            "Epoch 182/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4106 - acc: 0.8315\n",
            "Epoch 183/200\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4103 - acc: 0.8332\n",
            "Epoch 184/200\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4099 - acc: 0.8350\n",
            "Epoch 185/200\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4104 - acc: 0.8330\n",
            "Epoch 186/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4087 - acc: 0.8341\n",
            "Epoch 187/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4100 - acc: 0.8327\n",
            "Epoch 188/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4089 - acc: 0.8315\n",
            "Epoch 189/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4129 - acc: 0.8349\n",
            "Epoch 190/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4095 - acc: 0.8360\n",
            "Epoch 191/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4103 - acc: 0.8342\n",
            "Epoch 192/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4083 - acc: 0.8331\n",
            "Epoch 193/200\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4091 - acc: 0.8326\n",
            "Epoch 194/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4090 - acc: 0.8331\n",
            "Epoch 195/200\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4084 - acc: 0.8322\n",
            "Epoch 196/200\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4095 - acc: 0.8307\n",
            "Epoch 197/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4094 - acc: 0.8324\n",
            "Epoch 198/200\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4110 - acc: 0.8321\n",
            "Epoch 199/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4102 - acc: 0.8332\n",
            "Epoch 200/200\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4090 - acc: 0.8345\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f55d8f53b00>,\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'dropout_rate': [0.05, 0.2],\n",
              "                         'optimizer': ['RMSprop', 'adam']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwKqTo3P33yL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec47ceb6-65c8-4e48-c5e7-4a37827ff93b"
      },
      "source": [
        "grid_search.best_params_"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dropout_rate': 0.05, 'optimizer': 'RMSprop'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdxRTpnfFAQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuwdZ9KeFW1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = Sequential()\n",
        "classifier.add(Dense(units=8, input_dim =11 ,  activation='relu', kernel_initializer= 'uniform', use_bias=True ))\n",
        "classifier.add(Dropout(rate=0.05))\n",
        "\n",
        "classifier.add(Dense(units=6, activation='relu', kernel_initializer= 'uniform', use_bias=True))\n",
        "classifier.add(Dropout(rate=0.05))\n",
        "\n",
        "classifier.add(Dense(units=1, activation='sigmoid', kernel_initializer = 'uniform', use_bias=True))\n",
        "classifier.compile(optimizer='RMSprop', metrics=['accuracy'], loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMxBBJfDFm3W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6669345-0cb7-44e6-ea52-ece6a9ba7fdd"
      },
      "source": [
        "classifier.fit(train_x, train_y, batch_size=100, epochs=1000)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "8000/8000 [==============================] - 0s 60us/step - loss: 0.6646 - acc: 0.7897\n",
            "Epoch 2/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.5672 - acc: 0.7960\n",
            "Epoch 3/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4716 - acc: 0.7960\n",
            "Epoch 4/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4450 - acc: 0.7960\n",
            "Epoch 5/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4387 - acc: 0.7960\n",
            "Epoch 6/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4355 - acc: 0.7960\n",
            "Epoch 7/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4338 - acc: 0.7960\n",
            "Epoch 8/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4323 - acc: 0.7960\n",
            "Epoch 9/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4317 - acc: 0.7960\n",
            "Epoch 10/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4319 - acc: 0.7960\n",
            "Epoch 11/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4308 - acc: 0.7960\n",
            "Epoch 12/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4296 - acc: 0.7960\n",
            "Epoch 13/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4296 - acc: 0.7960\n",
            "Epoch 14/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4267 - acc: 0.7960\n",
            "Epoch 15/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4276 - acc: 0.7960\n",
            "Epoch 16/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4270 - acc: 0.7960\n",
            "Epoch 17/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4247 - acc: 0.7960\n",
            "Epoch 18/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4246 - acc: 0.7985\n",
            "Epoch 19/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4232 - acc: 0.8119\n",
            "Epoch 20/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4206 - acc: 0.8140\n",
            "Epoch 21/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4210 - acc: 0.8197\n",
            "Epoch 22/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4201 - acc: 0.8181\n",
            "Epoch 23/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4213 - acc: 0.8197\n",
            "Epoch 24/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4208 - acc: 0.8231\n",
            "Epoch 25/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4185 - acc: 0.8256\n",
            "Epoch 26/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4185 - acc: 0.8245\n",
            "Epoch 27/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4167 - acc: 0.8261\n",
            "Epoch 28/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4195 - acc: 0.8256\n",
            "Epoch 29/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4181 - acc: 0.8264\n",
            "Epoch 30/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4172 - acc: 0.8281\n",
            "Epoch 31/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4175 - acc: 0.8274\n",
            "Epoch 32/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4176 - acc: 0.8285\n",
            "Epoch 33/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4171 - acc: 0.8276\n",
            "Epoch 34/1000\n",
            "8000/8000 [==============================] - 0s 43us/step - loss: 0.4158 - acc: 0.8290\n",
            "Epoch 35/1000\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4187 - acc: 0.8275\n",
            "Epoch 36/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4178 - acc: 0.8287\n",
            "Epoch 37/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4174 - acc: 0.8284\n",
            "Epoch 38/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4159 - acc: 0.8271\n",
            "Epoch 39/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4156 - acc: 0.8311\n",
            "Epoch 40/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4165 - acc: 0.8301\n",
            "Epoch 41/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4165 - acc: 0.8296\n",
            "Epoch 42/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4160 - acc: 0.8279\n",
            "Epoch 43/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4147 - acc: 0.8310\n",
            "Epoch 44/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4162 - acc: 0.8320\n",
            "Epoch 45/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4159 - acc: 0.8302\n",
            "Epoch 46/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4144 - acc: 0.8301\n",
            "Epoch 47/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4157 - acc: 0.8295\n",
            "Epoch 48/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4153 - acc: 0.8299\n",
            "Epoch 49/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4145 - acc: 0.8321\n",
            "Epoch 50/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4146 - acc: 0.8322\n",
            "Epoch 51/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4167 - acc: 0.8320\n",
            "Epoch 52/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4166 - acc: 0.8325\n",
            "Epoch 53/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4145 - acc: 0.8331\n",
            "Epoch 54/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4178 - acc: 0.8317\n",
            "Epoch 55/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4124 - acc: 0.8311\n",
            "Epoch 56/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4158 - acc: 0.8321\n",
            "Epoch 57/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4140 - acc: 0.8294\n",
            "Epoch 58/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4145 - acc: 0.8287\n",
            "Epoch 59/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4151 - acc: 0.8299\n",
            "Epoch 60/1000\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4134 - acc: 0.8347\n",
            "Epoch 61/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4149 - acc: 0.8335\n",
            "Epoch 62/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4149 - acc: 0.8295\n",
            "Epoch 63/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4126 - acc: 0.8306\n",
            "Epoch 64/1000\n",
            "8000/8000 [==============================] - 0s 44us/step - loss: 0.4141 - acc: 0.8346\n",
            "Epoch 65/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4165 - acc: 0.8318\n",
            "Epoch 66/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4129 - acc: 0.8331\n",
            "Epoch 67/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4140 - acc: 0.8312\n",
            "Epoch 68/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4132 - acc: 0.8320\n",
            "Epoch 69/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4146 - acc: 0.8323\n",
            "Epoch 70/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4146 - acc: 0.8316\n",
            "Epoch 71/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4124 - acc: 0.8322\n",
            "Epoch 72/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4136 - acc: 0.8320\n",
            "Epoch 73/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4119 - acc: 0.8321\n",
            "Epoch 74/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4120 - acc: 0.8352\n",
            "Epoch 75/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4112 - acc: 0.8337\n",
            "Epoch 76/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4135 - acc: 0.8316\n",
            "Epoch 77/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4141 - acc: 0.8312\n",
            "Epoch 78/1000\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4139 - acc: 0.8301\n",
            "Epoch 79/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4126 - acc: 0.8325\n",
            "Epoch 80/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4137 - acc: 0.8321\n",
            "Epoch 81/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4132 - acc: 0.8319\n",
            "Epoch 82/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4131 - acc: 0.8306\n",
            "Epoch 83/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4112 - acc: 0.8346\n",
            "Epoch 84/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4129 - acc: 0.8321\n",
            "Epoch 85/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4116 - acc: 0.8361\n",
            "Epoch 86/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4128 - acc: 0.8320\n",
            "Epoch 87/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4107 - acc: 0.8299\n",
            "Epoch 88/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4129 - acc: 0.8325\n",
            "Epoch 89/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4128 - acc: 0.8328\n",
            "Epoch 90/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4124 - acc: 0.8335\n",
            "Epoch 91/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4140 - acc: 0.8311\n",
            "Epoch 92/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4116 - acc: 0.8337\n",
            "Epoch 93/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4136 - acc: 0.8320\n",
            "Epoch 94/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4101 - acc: 0.8331\n",
            "Epoch 95/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4151 - acc: 0.8302\n",
            "Epoch 96/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4136 - acc: 0.8309\n",
            "Epoch 97/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4129 - acc: 0.8303\n",
            "Epoch 98/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4136 - acc: 0.8302\n",
            "Epoch 99/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4117 - acc: 0.8318\n",
            "Epoch 100/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4097 - acc: 0.8306\n",
            "Epoch 101/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4139 - acc: 0.8321\n",
            "Epoch 102/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4138 - acc: 0.8315\n",
            "Epoch 103/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4111 - acc: 0.8313\n",
            "Epoch 104/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4124 - acc: 0.8322\n",
            "Epoch 105/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4117 - acc: 0.8324\n",
            "Epoch 106/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4131 - acc: 0.8320\n",
            "Epoch 107/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4102 - acc: 0.8337\n",
            "Epoch 108/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4096 - acc: 0.8340\n",
            "Epoch 109/1000\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4128 - acc: 0.8312\n",
            "Epoch 110/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4134 - acc: 0.8306\n",
            "Epoch 111/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4120 - acc: 0.8319\n",
            "Epoch 112/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4113 - acc: 0.8320\n",
            "Epoch 113/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4108 - acc: 0.8307\n",
            "Epoch 114/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4119 - acc: 0.8330\n",
            "Epoch 115/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4111 - acc: 0.8306\n",
            "Epoch 116/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4118 - acc: 0.8299\n",
            "Epoch 117/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4114 - acc: 0.8327\n",
            "Epoch 118/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4106 - acc: 0.8347\n",
            "Epoch 119/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4116 - acc: 0.8331\n",
            "Epoch 120/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4124 - acc: 0.8325\n",
            "Epoch 121/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4091 - acc: 0.8312\n",
            "Epoch 122/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4109 - acc: 0.8316\n",
            "Epoch 123/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4114 - acc: 0.8331\n",
            "Epoch 124/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4134 - acc: 0.8317\n",
            "Epoch 125/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4129 - acc: 0.8327\n",
            "Epoch 126/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4116 - acc: 0.8327\n",
            "Epoch 127/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4123 - acc: 0.8310\n",
            "Epoch 128/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4107 - acc: 0.8325\n",
            "Epoch 129/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4094 - acc: 0.8326\n",
            "Epoch 130/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4107 - acc: 0.8349\n",
            "Epoch 131/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4088 - acc: 0.8319\n",
            "Epoch 132/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4097 - acc: 0.8348\n",
            "Epoch 133/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4115 - acc: 0.8310\n",
            "Epoch 134/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4119 - acc: 0.8322\n",
            "Epoch 135/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4118 - acc: 0.8317\n",
            "Epoch 136/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4114 - acc: 0.8347\n",
            "Epoch 137/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4102 - acc: 0.8325\n",
            "Epoch 138/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4107 - acc: 0.8340\n",
            "Epoch 139/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4113 - acc: 0.8310\n",
            "Epoch 140/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4134 - acc: 0.8312\n",
            "Epoch 141/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4098 - acc: 0.8329\n",
            "Epoch 142/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4107 - acc: 0.8298\n",
            "Epoch 143/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4115 - acc: 0.8316\n",
            "Epoch 144/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4142 - acc: 0.8311\n",
            "Epoch 145/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4139 - acc: 0.8341\n",
            "Epoch 146/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4102 - acc: 0.8356\n",
            "Epoch 147/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4110 - acc: 0.8323\n",
            "Epoch 148/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4094 - acc: 0.8349\n",
            "Epoch 149/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4113 - acc: 0.8311\n",
            "Epoch 150/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4123 - acc: 0.8324\n",
            "Epoch 151/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4104 - acc: 0.8335\n",
            "Epoch 152/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4094 - acc: 0.8315\n",
            "Epoch 153/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4107 - acc: 0.8326\n",
            "Epoch 154/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4120 - acc: 0.8334\n",
            "Epoch 155/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4111 - acc: 0.8331\n",
            "Epoch 156/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4119 - acc: 0.8325\n",
            "Epoch 157/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4089 - acc: 0.8337\n",
            "Epoch 158/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4096 - acc: 0.8322\n",
            "Epoch 159/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4123 - acc: 0.8321\n",
            "Epoch 160/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4120 - acc: 0.8307\n",
            "Epoch 161/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4090 - acc: 0.8332\n",
            "Epoch 162/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4110 - acc: 0.8331\n",
            "Epoch 163/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4090 - acc: 0.8323\n",
            "Epoch 164/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4134 - acc: 0.8321\n",
            "Epoch 165/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4076 - acc: 0.8344\n",
            "Epoch 166/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4104 - acc: 0.8329\n",
            "Epoch 167/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4106 - acc: 0.8345\n",
            "Epoch 168/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4093 - acc: 0.8329\n",
            "Epoch 169/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4098 - acc: 0.8324\n",
            "Epoch 170/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4102 - acc: 0.8306\n",
            "Epoch 171/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4096 - acc: 0.8330\n",
            "Epoch 172/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4089 - acc: 0.8321\n",
            "Epoch 173/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4125 - acc: 0.8336\n",
            "Epoch 174/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4130 - acc: 0.8331\n",
            "Epoch 175/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4095 - acc: 0.8336\n",
            "Epoch 176/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4107 - acc: 0.8311\n",
            "Epoch 177/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4111 - acc: 0.8329\n",
            "Epoch 178/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4100 - acc: 0.8324\n",
            "Epoch 179/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4117 - acc: 0.8330\n",
            "Epoch 180/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4116 - acc: 0.8324\n",
            "Epoch 181/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4117 - acc: 0.8318\n",
            "Epoch 182/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4108 - acc: 0.8314\n",
            "Epoch 183/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4091 - acc: 0.8321\n",
            "Epoch 184/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4127 - acc: 0.8326\n",
            "Epoch 185/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4103 - acc: 0.8331\n",
            "Epoch 186/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4096 - acc: 0.8328\n",
            "Epoch 187/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4118 - acc: 0.8320\n",
            "Epoch 188/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4110 - acc: 0.8317\n",
            "Epoch 189/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4099 - acc: 0.8330\n",
            "Epoch 190/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4092 - acc: 0.8322\n",
            "Epoch 191/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4100 - acc: 0.8335\n",
            "Epoch 192/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4106 - acc: 0.8309\n",
            "Epoch 193/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4108 - acc: 0.8329\n",
            "Epoch 194/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4100 - acc: 0.8336\n",
            "Epoch 195/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4123 - acc: 0.8324\n",
            "Epoch 196/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4095 - acc: 0.8341\n",
            "Epoch 197/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4099 - acc: 0.8335\n",
            "Epoch 198/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4127 - acc: 0.8315\n",
            "Epoch 199/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4089 - acc: 0.8327\n",
            "Epoch 200/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4123 - acc: 0.8325\n",
            "Epoch 201/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4127 - acc: 0.8342\n",
            "Epoch 202/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4091 - acc: 0.8322\n",
            "Epoch 203/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4109 - acc: 0.8307\n",
            "Epoch 204/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4105 - acc: 0.8315\n",
            "Epoch 205/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4098 - acc: 0.8334\n",
            "Epoch 206/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4101 - acc: 0.8286\n",
            "Epoch 207/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4099 - acc: 0.8342\n",
            "Epoch 208/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4096 - acc: 0.8325\n",
            "Epoch 209/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4098 - acc: 0.8326\n",
            "Epoch 210/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4110 - acc: 0.8320\n",
            "Epoch 211/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4106 - acc: 0.8335\n",
            "Epoch 212/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4114 - acc: 0.8302\n",
            "Epoch 213/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4118 - acc: 0.8344\n",
            "Epoch 214/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4072 - acc: 0.8351\n",
            "Epoch 215/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4131 - acc: 0.8314\n",
            "Epoch 216/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4114 - acc: 0.8336\n",
            "Epoch 217/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4097 - acc: 0.8317\n",
            "Epoch 218/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4123 - acc: 0.8328\n",
            "Epoch 219/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4094 - acc: 0.8318\n",
            "Epoch 220/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4105 - acc: 0.8310\n",
            "Epoch 221/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4084 - acc: 0.8325\n",
            "Epoch 222/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4122 - acc: 0.8327\n",
            "Epoch 223/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4104 - acc: 0.8314\n",
            "Epoch 224/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4095 - acc: 0.8329\n",
            "Epoch 225/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4115 - acc: 0.8346\n",
            "Epoch 226/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4098 - acc: 0.8344\n",
            "Epoch 227/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4105 - acc: 0.8321\n",
            "Epoch 228/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4128 - acc: 0.8330\n",
            "Epoch 229/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4114 - acc: 0.8315\n",
            "Epoch 230/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4103 - acc: 0.8333\n",
            "Epoch 231/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4097 - acc: 0.8290\n",
            "Epoch 232/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4113 - acc: 0.8312\n",
            "Epoch 233/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4125 - acc: 0.8271\n",
            "Epoch 234/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4092 - acc: 0.8326\n",
            "Epoch 235/1000\n",
            "8000/8000 [==============================] - 0s 44us/step - loss: 0.4107 - acc: 0.8307\n",
            "Epoch 236/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4109 - acc: 0.8299\n",
            "Epoch 237/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4089 - acc: 0.8315\n",
            "Epoch 238/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4116 - acc: 0.8324\n",
            "Epoch 239/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4115 - acc: 0.8316\n",
            "Epoch 240/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4099 - acc: 0.8305\n",
            "Epoch 241/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4099 - acc: 0.8310\n",
            "Epoch 242/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4080 - acc: 0.8340\n",
            "Epoch 243/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4106 - acc: 0.8329\n",
            "Epoch 244/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4094 - acc: 0.8327\n",
            "Epoch 245/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4109 - acc: 0.8306\n",
            "Epoch 246/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4111 - acc: 0.8299\n",
            "Epoch 247/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4122 - acc: 0.8326\n",
            "Epoch 248/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4078 - acc: 0.8322\n",
            "Epoch 249/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4108 - acc: 0.8340\n",
            "Epoch 250/1000\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4101 - acc: 0.8321\n",
            "Epoch 251/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4112 - acc: 0.8340\n",
            "Epoch 252/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4111 - acc: 0.8338\n",
            "Epoch 253/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4091 - acc: 0.8321\n",
            "Epoch 254/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4083 - acc: 0.8337\n",
            "Epoch 255/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4098 - acc: 0.8328\n",
            "Epoch 256/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4105 - acc: 0.8324\n",
            "Epoch 257/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4090 - acc: 0.8331\n",
            "Epoch 258/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4117 - acc: 0.8307\n",
            "Epoch 259/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4098 - acc: 0.8321\n",
            "Epoch 260/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4093 - acc: 0.8334\n",
            "Epoch 261/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4093 - acc: 0.8345\n",
            "Epoch 262/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4094 - acc: 0.8315\n",
            "Epoch 263/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4094 - acc: 0.8334\n",
            "Epoch 264/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4109 - acc: 0.8339\n",
            "Epoch 265/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4090 - acc: 0.8321\n",
            "Epoch 266/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4122 - acc: 0.8314\n",
            "Epoch 267/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4082 - acc: 0.8316\n",
            "Epoch 268/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4112 - acc: 0.8307\n",
            "Epoch 269/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4066 - acc: 0.8335\n",
            "Epoch 270/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4083 - acc: 0.8309\n",
            "Epoch 271/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4111 - acc: 0.8344\n",
            "Epoch 272/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4102 - acc: 0.8316\n",
            "Epoch 273/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4080 - acc: 0.8329\n",
            "Epoch 274/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4101 - acc: 0.8331\n",
            "Epoch 275/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4105 - acc: 0.8337\n",
            "Epoch 276/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4112 - acc: 0.8321\n",
            "Epoch 277/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4101 - acc: 0.8323\n",
            "Epoch 278/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4099 - acc: 0.8334\n",
            "Epoch 279/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4107 - acc: 0.8300\n",
            "Epoch 280/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4101 - acc: 0.8339\n",
            "Epoch 281/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4112 - acc: 0.8326\n",
            "Epoch 282/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4107 - acc: 0.8300\n",
            "Epoch 283/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4087 - acc: 0.8322\n",
            "Epoch 284/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4100 - acc: 0.8336\n",
            "Epoch 285/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4112 - acc: 0.8311\n",
            "Epoch 286/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4117 - acc: 0.8310\n",
            "Epoch 287/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4084 - acc: 0.8320\n",
            "Epoch 288/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4118 - acc: 0.8311\n",
            "Epoch 289/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4101 - acc: 0.8348\n",
            "Epoch 290/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4089 - acc: 0.8320\n",
            "Epoch 291/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4095 - acc: 0.8334\n",
            "Epoch 292/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4091 - acc: 0.8315\n",
            "Epoch 293/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4139 - acc: 0.8294\n",
            "Epoch 294/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4113 - acc: 0.8306\n",
            "Epoch 295/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4094 - acc: 0.8329\n",
            "Epoch 296/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4111 - acc: 0.8332\n",
            "Epoch 297/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4100 - acc: 0.8344\n",
            "Epoch 298/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4079 - acc: 0.8314\n",
            "Epoch 299/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4084 - acc: 0.8321\n",
            "Epoch 300/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4105 - acc: 0.8326\n",
            "Epoch 301/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4097 - acc: 0.8314\n",
            "Epoch 302/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4072 - acc: 0.8342\n",
            "Epoch 303/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4114 - acc: 0.8326\n",
            "Epoch 304/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4112 - acc: 0.8324\n",
            "Epoch 305/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4087 - acc: 0.8342\n",
            "Epoch 306/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4096 - acc: 0.8336\n",
            "Epoch 307/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4109 - acc: 0.8323\n",
            "Epoch 308/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4055 - acc: 0.8296\n",
            "Epoch 309/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4087 - acc: 0.8344\n",
            "Epoch 310/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4057 - acc: 0.8344\n",
            "Epoch 311/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4117 - acc: 0.8324\n",
            "Epoch 312/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4106 - acc: 0.8335\n",
            "Epoch 313/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4081 - acc: 0.8321\n",
            "Epoch 314/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4128 - acc: 0.8284\n",
            "Epoch 315/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4106 - acc: 0.8325\n",
            "Epoch 316/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4076 - acc: 0.8311\n",
            "Epoch 317/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4106 - acc: 0.8299\n",
            "Epoch 318/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4101 - acc: 0.8339\n",
            "Epoch 319/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4102 - acc: 0.8306\n",
            "Epoch 320/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4105 - acc: 0.8293\n",
            "Epoch 321/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4121 - acc: 0.8342\n",
            "Epoch 322/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4072 - acc: 0.8320\n",
            "Epoch 323/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4083 - acc: 0.8305\n",
            "Epoch 324/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4090 - acc: 0.8310\n",
            "Epoch 325/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4089 - acc: 0.8344\n",
            "Epoch 326/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4097 - acc: 0.8321\n",
            "Epoch 327/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4117 - acc: 0.8320\n",
            "Epoch 328/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4103 - acc: 0.8324\n",
            "Epoch 329/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4108 - acc: 0.8337\n",
            "Epoch 330/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4105 - acc: 0.8340\n",
            "Epoch 331/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4090 - acc: 0.8310\n",
            "Epoch 332/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4106 - acc: 0.8303\n",
            "Epoch 333/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4098 - acc: 0.8326\n",
            "Epoch 334/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4092 - acc: 0.8332\n",
            "Epoch 335/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4088 - acc: 0.8324\n",
            "Epoch 336/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4122 - acc: 0.8305\n",
            "Epoch 337/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4108 - acc: 0.8316\n",
            "Epoch 338/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4093 - acc: 0.8324\n",
            "Epoch 339/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4094 - acc: 0.8327\n",
            "Epoch 340/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4087 - acc: 0.8303\n",
            "Epoch 341/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4099 - acc: 0.8325\n",
            "Epoch 342/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4125 - acc: 0.8312\n",
            "Epoch 343/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4107 - acc: 0.8331\n",
            "Epoch 344/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4066 - acc: 0.8330\n",
            "Epoch 345/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4097 - acc: 0.8346\n",
            "Epoch 346/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4115 - acc: 0.8309\n",
            "Epoch 347/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4120 - acc: 0.8320\n",
            "Epoch 348/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4103 - acc: 0.8324\n",
            "Epoch 349/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4110 - acc: 0.8340\n",
            "Epoch 350/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4065 - acc: 0.8348\n",
            "Epoch 351/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4093 - acc: 0.8339\n",
            "Epoch 352/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4100 - acc: 0.8317\n",
            "Epoch 353/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4085 - acc: 0.8329\n",
            "Epoch 354/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4089 - acc: 0.8326\n",
            "Epoch 355/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4095 - acc: 0.8320\n",
            "Epoch 356/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4100 - acc: 0.8338\n",
            "Epoch 357/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4069 - acc: 0.8337\n",
            "Epoch 358/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4088 - acc: 0.8340\n",
            "Epoch 359/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4085 - acc: 0.8329\n",
            "Epoch 360/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4110 - acc: 0.8325\n",
            "Epoch 361/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4057 - acc: 0.8315\n",
            "Epoch 362/1000\n",
            "8000/8000 [==============================] - 0s 43us/step - loss: 0.4090 - acc: 0.8319\n",
            "Epoch 363/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4121 - acc: 0.8331\n",
            "Epoch 364/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4062 - acc: 0.8341\n",
            "Epoch 365/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4091 - acc: 0.8319\n",
            "Epoch 366/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4095 - acc: 0.8312\n",
            "Epoch 367/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4091 - acc: 0.8337\n",
            "Epoch 368/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4094 - acc: 0.8354\n",
            "Epoch 369/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4112 - acc: 0.8320\n",
            "Epoch 370/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4091 - acc: 0.8329\n",
            "Epoch 371/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4125 - acc: 0.8312\n",
            "Epoch 372/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4120 - acc: 0.8317\n",
            "Epoch 373/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4110 - acc: 0.8327\n",
            "Epoch 374/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4075 - acc: 0.8337\n",
            "Epoch 375/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4092 - acc: 0.8314\n",
            "Epoch 376/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4065 - acc: 0.8331\n",
            "Epoch 377/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4105 - acc: 0.8320\n",
            "Epoch 378/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4099 - acc: 0.8300\n",
            "Epoch 379/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4094 - acc: 0.8336\n",
            "Epoch 380/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4083 - acc: 0.8324\n",
            "Epoch 381/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4111 - acc: 0.8297\n",
            "Epoch 382/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4093 - acc: 0.8329\n",
            "Epoch 383/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4097 - acc: 0.8317\n",
            "Epoch 384/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4094 - acc: 0.8309\n",
            "Epoch 385/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4080 - acc: 0.8346\n",
            "Epoch 386/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4126 - acc: 0.8329\n",
            "Epoch 387/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4084 - acc: 0.8309\n",
            "Epoch 388/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4110 - acc: 0.8339\n",
            "Epoch 389/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4096 - acc: 0.8324\n",
            "Epoch 390/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4073 - acc: 0.8336\n",
            "Epoch 391/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4094 - acc: 0.8337\n",
            "Epoch 392/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4092 - acc: 0.8336\n",
            "Epoch 393/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4112 - acc: 0.8307\n",
            "Epoch 394/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4098 - acc: 0.8312\n",
            "Epoch 395/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4106 - acc: 0.8332\n",
            "Epoch 396/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4092 - acc: 0.8325\n",
            "Epoch 397/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4083 - acc: 0.8344\n",
            "Epoch 398/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4091 - acc: 0.8340\n",
            "Epoch 399/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4104 - acc: 0.8337\n",
            "Epoch 400/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4076 - acc: 0.8312\n",
            "Epoch 401/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4096 - acc: 0.8331\n",
            "Epoch 402/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4073 - acc: 0.8332\n",
            "Epoch 403/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4095 - acc: 0.8314\n",
            "Epoch 404/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4098 - acc: 0.8294\n",
            "Epoch 405/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4116 - acc: 0.8316\n",
            "Epoch 406/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4086 - acc: 0.8337\n",
            "Epoch 407/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4106 - acc: 0.8334\n",
            "Epoch 408/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4078 - acc: 0.8331\n",
            "Epoch 409/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4122 - acc: 0.8331\n",
            "Epoch 410/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4089 - acc: 0.8330\n",
            "Epoch 411/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4081 - acc: 0.8319\n",
            "Epoch 412/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4093 - acc: 0.8340\n",
            "Epoch 413/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4119 - acc: 0.8324\n",
            "Epoch 414/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4072 - acc: 0.8332\n",
            "Epoch 415/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4086 - acc: 0.8324\n",
            "Epoch 416/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4081 - acc: 0.8326\n",
            "Epoch 417/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4098 - acc: 0.8330\n",
            "Epoch 418/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4112 - acc: 0.8326\n",
            "Epoch 419/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4136 - acc: 0.8306\n",
            "Epoch 420/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4092 - acc: 0.8330\n",
            "Epoch 421/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4087 - acc: 0.8325\n",
            "Epoch 422/1000\n",
            "8000/8000 [==============================] - 0s 44us/step - loss: 0.4095 - acc: 0.8311\n",
            "Epoch 423/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4068 - acc: 0.8331\n",
            "Epoch 424/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4088 - acc: 0.8311\n",
            "Epoch 425/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4093 - acc: 0.8305\n",
            "Epoch 426/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4097 - acc: 0.8335\n",
            "Epoch 427/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4112 - acc: 0.8311\n",
            "Epoch 428/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4109 - acc: 0.8316\n",
            "Epoch 429/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4110 - acc: 0.8307\n",
            "Epoch 430/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4107 - acc: 0.8335\n",
            "Epoch 431/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4100 - acc: 0.8334\n",
            "Epoch 432/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4138 - acc: 0.8342\n",
            "Epoch 433/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4104 - acc: 0.8321\n",
            "Epoch 434/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4093 - acc: 0.8330\n",
            "Epoch 435/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4065 - acc: 0.8315\n",
            "Epoch 436/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4109 - acc: 0.8340\n",
            "Epoch 437/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4093 - acc: 0.8327\n",
            "Epoch 438/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4111 - acc: 0.8317\n",
            "Epoch 439/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4116 - acc: 0.8333\n",
            "Epoch 440/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4122 - acc: 0.8327\n",
            "Epoch 441/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4088 - acc: 0.8332\n",
            "Epoch 442/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4108 - acc: 0.8332\n",
            "Epoch 443/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4089 - acc: 0.8325\n",
            "Epoch 444/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4090 - acc: 0.8317\n",
            "Epoch 445/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4077 - acc: 0.8335\n",
            "Epoch 446/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4104 - acc: 0.8339\n",
            "Epoch 447/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4082 - acc: 0.8320\n",
            "Epoch 448/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4102 - acc: 0.8326\n",
            "Epoch 449/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4095 - acc: 0.8344\n",
            "Epoch 450/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4092 - acc: 0.8341\n",
            "Epoch 451/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4098 - acc: 0.8306\n",
            "Epoch 452/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4103 - acc: 0.8316\n",
            "Epoch 453/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4108 - acc: 0.8313\n",
            "Epoch 454/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4091 - acc: 0.8317\n",
            "Epoch 455/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4081 - acc: 0.8326\n",
            "Epoch 456/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4080 - acc: 0.8326\n",
            "Epoch 457/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4087 - acc: 0.8322\n",
            "Epoch 458/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4100 - acc: 0.8322\n",
            "Epoch 459/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4103 - acc: 0.8312\n",
            "Epoch 460/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4091 - acc: 0.8311\n",
            "Epoch 461/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4077 - acc: 0.8322\n",
            "Epoch 462/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4086 - acc: 0.8339\n",
            "Epoch 463/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4110 - acc: 0.8312\n",
            "Epoch 464/1000\n",
            "8000/8000 [==============================] - 0s 45us/step - loss: 0.4098 - acc: 0.8297\n",
            "Epoch 465/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4098 - acc: 0.8330\n",
            "Epoch 466/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4068 - acc: 0.8332\n",
            "Epoch 467/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4105 - acc: 0.8327\n",
            "Epoch 468/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4094 - acc: 0.8344\n",
            "Epoch 469/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4103 - acc: 0.8324\n",
            "Epoch 470/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4092 - acc: 0.8336\n",
            "Epoch 471/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4071 - acc: 0.8317\n",
            "Epoch 472/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4078 - acc: 0.8330\n",
            "Epoch 473/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4097 - acc: 0.8339\n",
            "Epoch 474/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4097 - acc: 0.8327\n",
            "Epoch 475/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4089 - acc: 0.8335\n",
            "Epoch 476/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4087 - acc: 0.8347\n",
            "Epoch 477/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4088 - acc: 0.8349\n",
            "Epoch 478/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4108 - acc: 0.8325\n",
            "Epoch 479/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4096 - acc: 0.8324\n",
            "Epoch 480/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4088 - acc: 0.8307\n",
            "Epoch 481/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4098 - acc: 0.8322\n",
            "Epoch 482/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4080 - acc: 0.8330\n",
            "Epoch 483/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4104 - acc: 0.8309\n",
            "Epoch 484/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4090 - acc: 0.8330\n",
            "Epoch 485/1000\n",
            "8000/8000 [==============================] - 0s 28us/step - loss: 0.4088 - acc: 0.8326\n",
            "Epoch 486/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4103 - acc: 0.8330\n",
            "Epoch 487/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4095 - acc: 0.8339\n",
            "Epoch 488/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4103 - acc: 0.8326\n",
            "Epoch 489/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4113 - acc: 0.8301\n",
            "Epoch 490/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4099 - acc: 0.8314\n",
            "Epoch 491/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4099 - acc: 0.8365\n",
            "Epoch 492/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4067 - acc: 0.8341\n",
            "Epoch 493/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4067 - acc: 0.8316\n",
            "Epoch 494/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4109 - acc: 0.8311\n",
            "Epoch 495/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4082 - acc: 0.8335\n",
            "Epoch 496/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4098 - acc: 0.8330\n",
            "Epoch 497/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4104 - acc: 0.8329\n",
            "Epoch 498/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4087 - acc: 0.8328\n",
            "Epoch 499/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4122 - acc: 0.8300\n",
            "Epoch 500/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4093 - acc: 0.8315\n",
            "Epoch 501/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4086 - acc: 0.8336\n",
            "Epoch 502/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4097 - acc: 0.8322\n",
            "Epoch 503/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4083 - acc: 0.8349\n",
            "Epoch 504/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4114 - acc: 0.8319\n",
            "Epoch 505/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4060 - acc: 0.8335\n",
            "Epoch 506/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4105 - acc: 0.8310\n",
            "Epoch 507/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4114 - acc: 0.8306\n",
            "Epoch 508/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4090 - acc: 0.8325\n",
            "Epoch 509/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4087 - acc: 0.8309\n",
            "Epoch 510/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4096 - acc: 0.8336\n",
            "Epoch 511/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4087 - acc: 0.8320\n",
            "Epoch 512/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4133 - acc: 0.8318\n",
            "Epoch 513/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4096 - acc: 0.8331\n",
            "Epoch 514/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4088 - acc: 0.8341\n",
            "Epoch 515/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4102 - acc: 0.8311\n",
            "Epoch 516/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4093 - acc: 0.8311\n",
            "Epoch 517/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4094 - acc: 0.8334\n",
            "Epoch 518/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4096 - acc: 0.8321\n",
            "Epoch 519/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4088 - acc: 0.8312\n",
            "Epoch 520/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4096 - acc: 0.8334\n",
            "Epoch 521/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4107 - acc: 0.8333\n",
            "Epoch 522/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4094 - acc: 0.8324\n",
            "Epoch 523/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4092 - acc: 0.8326\n",
            "Epoch 524/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4102 - acc: 0.8346\n",
            "Epoch 525/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4107 - acc: 0.8327\n",
            "Epoch 526/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4116 - acc: 0.8336\n",
            "Epoch 527/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4115 - acc: 0.8309\n",
            "Epoch 528/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4096 - acc: 0.8334\n",
            "Epoch 529/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4114 - acc: 0.8324\n",
            "Epoch 530/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4082 - acc: 0.8342\n",
            "Epoch 531/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4079 - acc: 0.8310\n",
            "Epoch 532/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4102 - acc: 0.8337\n",
            "Epoch 533/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4100 - acc: 0.8344\n",
            "Epoch 534/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4103 - acc: 0.8329\n",
            "Epoch 535/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4089 - acc: 0.8321\n",
            "Epoch 536/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4107 - acc: 0.8332\n",
            "Epoch 537/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4080 - acc: 0.8343\n",
            "Epoch 538/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4098 - acc: 0.8342\n",
            "Epoch 539/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4109 - acc: 0.8338\n",
            "Epoch 540/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4097 - acc: 0.8337\n",
            "Epoch 541/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4085 - acc: 0.8334\n",
            "Epoch 542/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4068 - acc: 0.8323\n",
            "Epoch 543/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4093 - acc: 0.8339\n",
            "Epoch 544/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4074 - acc: 0.8342\n",
            "Epoch 545/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4098 - acc: 0.8337\n",
            "Epoch 546/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4091 - acc: 0.8332\n",
            "Epoch 547/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4100 - acc: 0.8328\n",
            "Epoch 548/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4092 - acc: 0.8330\n",
            "Epoch 549/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4101 - acc: 0.8337\n",
            "Epoch 550/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4100 - acc: 0.8322\n",
            "Epoch 551/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4087 - acc: 0.8346\n",
            "Epoch 552/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4095 - acc: 0.8344\n",
            "Epoch 553/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4099 - acc: 0.8324\n",
            "Epoch 554/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4082 - acc: 0.8365\n",
            "Epoch 555/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4086 - acc: 0.8344\n",
            "Epoch 556/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4104 - acc: 0.8331\n",
            "Epoch 557/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4094 - acc: 0.8335\n",
            "Epoch 558/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4075 - acc: 0.8340\n",
            "Epoch 559/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4085 - acc: 0.8331\n",
            "Epoch 560/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4130 - acc: 0.8324\n",
            "Epoch 561/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4096 - acc: 0.8343\n",
            "Epoch 562/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4087 - acc: 0.8326\n",
            "Epoch 563/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4098 - acc: 0.8339\n",
            "Epoch 564/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4075 - acc: 0.8328\n",
            "Epoch 565/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4117 - acc: 0.8335\n",
            "Epoch 566/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4091 - acc: 0.8329\n",
            "Epoch 567/1000\n",
            "8000/8000 [==============================] - 0s 43us/step - loss: 0.4115 - acc: 0.8308\n",
            "Epoch 568/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4087 - acc: 0.8320\n",
            "Epoch 569/1000\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4109 - acc: 0.8335\n",
            "Epoch 570/1000\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4108 - acc: 0.8324\n",
            "Epoch 571/1000\n",
            "8000/8000 [==============================] - 0s 43us/step - loss: 0.4088 - acc: 0.8340\n",
            "Epoch 572/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4089 - acc: 0.8319\n",
            "Epoch 573/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4084 - acc: 0.8342\n",
            "Epoch 574/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4071 - acc: 0.8321\n",
            "Epoch 575/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4076 - acc: 0.8348\n",
            "Epoch 576/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4088 - acc: 0.8326\n",
            "Epoch 577/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4101 - acc: 0.8327\n",
            "Epoch 578/1000\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4095 - acc: 0.8346\n",
            "Epoch 579/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4081 - acc: 0.8334\n",
            "Epoch 580/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4061 - acc: 0.8330\n",
            "Epoch 581/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4102 - acc: 0.8344\n",
            "Epoch 582/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4125 - acc: 0.8338\n",
            "Epoch 583/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4112 - acc: 0.8330\n",
            "Epoch 584/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4095 - acc: 0.8307\n",
            "Epoch 585/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4077 - acc: 0.8335\n",
            "Epoch 586/1000\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4104 - acc: 0.8320\n",
            "Epoch 587/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4095 - acc: 0.8327\n",
            "Epoch 588/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4074 - acc: 0.8374\n",
            "Epoch 589/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4074 - acc: 0.8334\n",
            "Epoch 590/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4055 - acc: 0.8337\n",
            "Epoch 591/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4101 - acc: 0.8315\n",
            "Epoch 592/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4096 - acc: 0.8342\n",
            "Epoch 593/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4089 - acc: 0.8341\n",
            "Epoch 594/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4094 - acc: 0.8341\n",
            "Epoch 595/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4088 - acc: 0.8349\n",
            "Epoch 596/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4102 - acc: 0.8349\n",
            "Epoch 597/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4094 - acc: 0.8331\n",
            "Epoch 598/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4080 - acc: 0.8357\n",
            "Epoch 599/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4119 - acc: 0.8329\n",
            "Epoch 600/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4118 - acc: 0.8320\n",
            "Epoch 601/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4113 - acc: 0.8339\n",
            "Epoch 602/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4088 - acc: 0.8340\n",
            "Epoch 603/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4094 - acc: 0.8325\n",
            "Epoch 604/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4087 - acc: 0.8331\n",
            "Epoch 605/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4095 - acc: 0.8347\n",
            "Epoch 606/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4093 - acc: 0.8324\n",
            "Epoch 607/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4112 - acc: 0.8332\n",
            "Epoch 608/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4089 - acc: 0.8328\n",
            "Epoch 609/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4086 - acc: 0.8326\n",
            "Epoch 610/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4087 - acc: 0.8315\n",
            "Epoch 611/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4088 - acc: 0.8340\n",
            "Epoch 612/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4114 - acc: 0.8357\n",
            "Epoch 613/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4091 - acc: 0.8304\n",
            "Epoch 614/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4068 - acc: 0.8380\n",
            "Epoch 615/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4087 - acc: 0.8330\n",
            "Epoch 616/1000\n",
            "8000/8000 [==============================] - 0s 43us/step - loss: 0.4094 - acc: 0.8351\n",
            "Epoch 617/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4090 - acc: 0.8361\n",
            "Epoch 618/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4078 - acc: 0.8330\n",
            "Epoch 619/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4083 - acc: 0.8330\n",
            "Epoch 620/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4087 - acc: 0.8321\n",
            "Epoch 621/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4115 - acc: 0.8329\n",
            "Epoch 622/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4090 - acc: 0.8326\n",
            "Epoch 623/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4109 - acc: 0.8345\n",
            "Epoch 624/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4100 - acc: 0.8317\n",
            "Epoch 625/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4074 - acc: 0.8341\n",
            "Epoch 626/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4098 - acc: 0.8321\n",
            "Epoch 627/1000\n",
            "8000/8000 [==============================] - 0s 44us/step - loss: 0.4090 - acc: 0.8341\n",
            "Epoch 628/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4097 - acc: 0.8335\n",
            "Epoch 629/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4100 - acc: 0.8344\n",
            "Epoch 630/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4102 - acc: 0.8338\n",
            "Epoch 631/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4103 - acc: 0.8320\n",
            "Epoch 632/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4082 - acc: 0.8333\n",
            "Epoch 633/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4081 - acc: 0.8345\n",
            "Epoch 634/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4090 - acc: 0.8332\n",
            "Epoch 635/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4073 - acc: 0.8345\n",
            "Epoch 636/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4098 - acc: 0.8341\n",
            "Epoch 637/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4089 - acc: 0.8362\n",
            "Epoch 638/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4101 - acc: 0.8340\n",
            "Epoch 639/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4108 - acc: 0.8354\n",
            "Epoch 640/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4091 - acc: 0.8324\n",
            "Epoch 641/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4110 - acc: 0.8345\n",
            "Epoch 642/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4079 - acc: 0.8327\n",
            "Epoch 643/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4072 - acc: 0.8345\n",
            "Epoch 644/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4079 - acc: 0.8355\n",
            "Epoch 645/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4106 - acc: 0.8342\n",
            "Epoch 646/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4101 - acc: 0.8350\n",
            "Epoch 647/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4087 - acc: 0.8328\n",
            "Epoch 648/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4081 - acc: 0.8347\n",
            "Epoch 649/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4108 - acc: 0.8345\n",
            "Epoch 650/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4069 - acc: 0.8337\n",
            "Epoch 651/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4087 - acc: 0.8329\n",
            "Epoch 652/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4096 - acc: 0.8344\n",
            "Epoch 653/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4083 - acc: 0.8339\n",
            "Epoch 654/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4106 - acc: 0.8355\n",
            "Epoch 655/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4093 - acc: 0.8345\n",
            "Epoch 656/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4077 - acc: 0.8338\n",
            "Epoch 657/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4108 - acc: 0.8354\n",
            "Epoch 658/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4098 - acc: 0.8334\n",
            "Epoch 659/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4104 - acc: 0.8320\n",
            "Epoch 660/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4075 - acc: 0.8340\n",
            "Epoch 661/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4079 - acc: 0.8316\n",
            "Epoch 662/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4101 - acc: 0.8339\n",
            "Epoch 663/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4076 - acc: 0.8364\n",
            "Epoch 664/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4077 - acc: 0.8309\n",
            "Epoch 665/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4072 - acc: 0.8335\n",
            "Epoch 666/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4091 - acc: 0.8349\n",
            "Epoch 667/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4087 - acc: 0.8331\n",
            "Epoch 668/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4081 - acc: 0.8347\n",
            "Epoch 669/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4115 - acc: 0.8357\n",
            "Epoch 670/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4088 - acc: 0.8344\n",
            "Epoch 671/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4084 - acc: 0.8341\n",
            "Epoch 672/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4064 - acc: 0.8363\n",
            "Epoch 673/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4099 - acc: 0.8346\n",
            "Epoch 674/1000\n",
            "8000/8000 [==============================] - 0s 28us/step - loss: 0.4101 - acc: 0.8331\n",
            "Epoch 675/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4085 - acc: 0.8341\n",
            "Epoch 676/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4086 - acc: 0.8326\n",
            "Epoch 677/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4074 - acc: 0.8337\n",
            "Epoch 678/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4113 - acc: 0.8342\n",
            "Epoch 679/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4087 - acc: 0.8347\n",
            "Epoch 680/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4095 - acc: 0.8359\n",
            "Epoch 681/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4078 - acc: 0.8344\n",
            "Epoch 682/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4082 - acc: 0.8332\n",
            "Epoch 683/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4111 - acc: 0.8345\n",
            "Epoch 684/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4072 - acc: 0.8344\n",
            "Epoch 685/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4079 - acc: 0.8346\n",
            "Epoch 686/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4092 - acc: 0.8320\n",
            "Epoch 687/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4082 - acc: 0.8343\n",
            "Epoch 688/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4087 - acc: 0.8346\n",
            "Epoch 689/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4106 - acc: 0.8335\n",
            "Epoch 690/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4118 - acc: 0.8346\n",
            "Epoch 691/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4098 - acc: 0.8327\n",
            "Epoch 692/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4072 - acc: 0.8341\n",
            "Epoch 693/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4103 - acc: 0.8319\n",
            "Epoch 694/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4081 - acc: 0.8336\n",
            "Epoch 695/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4093 - acc: 0.8340\n",
            "Epoch 696/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4113 - acc: 0.8355\n",
            "Epoch 697/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4080 - acc: 0.8342\n",
            "Epoch 698/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4077 - acc: 0.8339\n",
            "Epoch 699/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4085 - acc: 0.8321\n",
            "Epoch 700/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4080 - acc: 0.8364\n",
            "Epoch 701/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4092 - acc: 0.8339\n",
            "Epoch 702/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4068 - acc: 0.8341\n",
            "Epoch 703/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4072 - acc: 0.8357\n",
            "Epoch 704/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4105 - acc: 0.8324\n",
            "Epoch 705/1000\n",
            "8000/8000 [==============================] - 0s 43us/step - loss: 0.4081 - acc: 0.8359\n",
            "Epoch 706/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4059 - acc: 0.8346\n",
            "Epoch 707/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4102 - acc: 0.8330\n",
            "Epoch 708/1000\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4081 - acc: 0.8346\n",
            "Epoch 709/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4083 - acc: 0.8346\n",
            "Epoch 710/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4097 - acc: 0.8360\n",
            "Epoch 711/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4085 - acc: 0.8365\n",
            "Epoch 712/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4087 - acc: 0.8337\n",
            "Epoch 713/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4092 - acc: 0.8361\n",
            "Epoch 714/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4074 - acc: 0.8361\n",
            "Epoch 715/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4086 - acc: 0.8348\n",
            "Epoch 716/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4078 - acc: 0.8335\n",
            "Epoch 717/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4085 - acc: 0.8361\n",
            "Epoch 718/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4086 - acc: 0.8349\n",
            "Epoch 719/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4103 - acc: 0.8357\n",
            "Epoch 720/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4085 - acc: 0.8342\n",
            "Epoch 721/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4074 - acc: 0.8369\n",
            "Epoch 722/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4089 - acc: 0.8344\n",
            "Epoch 723/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4084 - acc: 0.8364\n",
            "Epoch 724/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4082 - acc: 0.8356\n",
            "Epoch 725/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4049 - acc: 0.8361\n",
            "Epoch 726/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4095 - acc: 0.8341\n",
            "Epoch 727/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4066 - acc: 0.8344\n",
            "Epoch 728/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4084 - acc: 0.8358\n",
            "Epoch 729/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4096 - acc: 0.8358\n",
            "Epoch 730/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4086 - acc: 0.8346\n",
            "Epoch 731/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4090 - acc: 0.8333\n",
            "Epoch 732/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4112 - acc: 0.8324\n",
            "Epoch 733/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4085 - acc: 0.8350\n",
            "Epoch 734/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4069 - acc: 0.8346\n",
            "Epoch 735/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4106 - acc: 0.8329\n",
            "Epoch 736/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4109 - acc: 0.8361\n",
            "Epoch 737/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4068 - acc: 0.8340\n",
            "Epoch 738/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4098 - acc: 0.8337\n",
            "Epoch 739/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4083 - acc: 0.8344\n",
            "Epoch 740/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4079 - acc: 0.8356\n",
            "Epoch 741/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4087 - acc: 0.8355\n",
            "Epoch 742/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4091 - acc: 0.8341\n",
            "Epoch 743/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4102 - acc: 0.8354\n",
            "Epoch 744/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4095 - acc: 0.8336\n",
            "Epoch 745/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4103 - acc: 0.8349\n",
            "Epoch 746/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4067 - acc: 0.8349\n",
            "Epoch 747/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4074 - acc: 0.8349\n",
            "Epoch 748/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4098 - acc: 0.8342\n",
            "Epoch 749/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4093 - acc: 0.8347\n",
            "Epoch 750/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4072 - acc: 0.8362\n",
            "Epoch 751/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4086 - acc: 0.8334\n",
            "Epoch 752/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4080 - acc: 0.8342\n",
            "Epoch 753/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4086 - acc: 0.8350\n",
            "Epoch 754/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4073 - acc: 0.8341\n",
            "Epoch 755/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4085 - acc: 0.8356\n",
            "Epoch 756/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4074 - acc: 0.8360\n",
            "Epoch 757/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4063 - acc: 0.8355\n",
            "Epoch 758/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4061 - acc: 0.8356\n",
            "Epoch 759/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4097 - acc: 0.8350\n",
            "Epoch 760/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4073 - acc: 0.8335\n",
            "Epoch 761/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4068 - acc: 0.8337\n",
            "Epoch 762/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4061 - acc: 0.8364\n",
            "Epoch 763/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4086 - acc: 0.8350\n",
            "Epoch 764/1000\n",
            "8000/8000 [==============================] - 0s 44us/step - loss: 0.4044 - acc: 0.8344\n",
            "Epoch 765/1000\n",
            "8000/8000 [==============================] - 0s 43us/step - loss: 0.4075 - acc: 0.8319\n",
            "Epoch 766/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4086 - acc: 0.8319\n",
            "Epoch 767/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4062 - acc: 0.8337\n",
            "Epoch 768/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4092 - acc: 0.8342\n",
            "Epoch 769/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4096 - acc: 0.8354\n",
            "Epoch 770/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4086 - acc: 0.8348\n",
            "Epoch 771/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4074 - acc: 0.8340\n",
            "Epoch 772/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4067 - acc: 0.8342\n",
            "Epoch 773/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4064 - acc: 0.8356\n",
            "Epoch 774/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4089 - acc: 0.8356\n",
            "Epoch 775/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4088 - acc: 0.8337\n",
            "Epoch 776/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4076 - acc: 0.8372\n",
            "Epoch 777/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4080 - acc: 0.8339\n",
            "Epoch 778/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4098 - acc: 0.8367\n",
            "Epoch 779/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4102 - acc: 0.8354\n",
            "Epoch 780/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4061 - acc: 0.8351\n",
            "Epoch 781/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4071 - acc: 0.8349\n",
            "Epoch 782/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4084 - acc: 0.8350\n",
            "Epoch 783/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4101 - acc: 0.8326\n",
            "Epoch 784/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4066 - acc: 0.8351\n",
            "Epoch 785/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4076 - acc: 0.8371\n",
            "Epoch 786/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4082 - acc: 0.8367\n",
            "Epoch 787/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4082 - acc: 0.8339\n",
            "Epoch 788/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4058 - acc: 0.8349\n",
            "Epoch 789/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4074 - acc: 0.8327\n",
            "Epoch 790/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4072 - acc: 0.8358\n",
            "Epoch 791/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4081 - acc: 0.8341\n",
            "Epoch 792/1000\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4076 - acc: 0.8353\n",
            "Epoch 793/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4059 - acc: 0.8351\n",
            "Epoch 794/1000\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4054 - acc: 0.8347\n",
            "Epoch 795/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4069 - acc: 0.8355\n",
            "Epoch 796/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4068 - acc: 0.8360\n",
            "Epoch 797/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4064 - acc: 0.8344\n",
            "Epoch 798/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4107 - acc: 0.8330\n",
            "Epoch 799/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4098 - acc: 0.8357\n",
            "Epoch 800/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4078 - acc: 0.8349\n",
            "Epoch 801/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4107 - acc: 0.8345\n",
            "Epoch 802/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4072 - acc: 0.8354\n",
            "Epoch 803/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4086 - acc: 0.8356\n",
            "Epoch 804/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4084 - acc: 0.8349\n",
            "Epoch 805/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4087 - acc: 0.8336\n",
            "Epoch 806/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4090 - acc: 0.8357\n",
            "Epoch 807/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4092 - acc: 0.8333\n",
            "Epoch 808/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4087 - acc: 0.8343\n",
            "Epoch 809/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4078 - acc: 0.8345\n",
            "Epoch 810/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4065 - acc: 0.8364\n",
            "Epoch 811/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4099 - acc: 0.8349\n",
            "Epoch 812/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4086 - acc: 0.8350\n",
            "Epoch 813/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4094 - acc: 0.8344\n",
            "Epoch 814/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4098 - acc: 0.8350\n",
            "Epoch 815/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4077 - acc: 0.8352\n",
            "Epoch 816/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4093 - acc: 0.8347\n",
            "Epoch 817/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4061 - acc: 0.8355\n",
            "Epoch 818/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4067 - acc: 0.8356\n",
            "Epoch 819/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4095 - acc: 0.8354\n",
            "Epoch 820/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4079 - acc: 0.8316\n",
            "Epoch 821/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4101 - acc: 0.8316\n",
            "Epoch 822/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4069 - acc: 0.8359\n",
            "Epoch 823/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4073 - acc: 0.8344\n",
            "Epoch 824/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4082 - acc: 0.8340\n",
            "Epoch 825/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4080 - acc: 0.8352\n",
            "Epoch 826/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4067 - acc: 0.8352\n",
            "Epoch 827/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4064 - acc: 0.8347\n",
            "Epoch 828/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4092 - acc: 0.8344\n",
            "Epoch 829/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4064 - acc: 0.8349\n",
            "Epoch 830/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4082 - acc: 0.8344\n",
            "Epoch 831/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4091 - acc: 0.8324\n",
            "Epoch 832/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4106 - acc: 0.8327\n",
            "Epoch 833/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4081 - acc: 0.8335\n",
            "Epoch 834/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4063 - acc: 0.8340\n",
            "Epoch 835/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4109 - acc: 0.8356\n",
            "Epoch 836/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4062 - acc: 0.8351\n",
            "Epoch 837/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4060 - acc: 0.8362\n",
            "Epoch 838/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4080 - acc: 0.8339\n",
            "Epoch 839/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4081 - acc: 0.8356\n",
            "Epoch 840/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4087 - acc: 0.8369\n",
            "Epoch 841/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4067 - acc: 0.8356\n",
            "Epoch 842/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4067 - acc: 0.8379\n",
            "Epoch 843/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4076 - acc: 0.8358\n",
            "Epoch 844/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4079 - acc: 0.8352\n",
            "Epoch 845/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4102 - acc: 0.8345\n",
            "Epoch 846/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4090 - acc: 0.8352\n",
            "Epoch 847/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4098 - acc: 0.8362\n",
            "Epoch 848/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4092 - acc: 0.8342\n",
            "Epoch 849/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4060 - acc: 0.8335\n",
            "Epoch 850/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4093 - acc: 0.8344\n",
            "Epoch 851/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4097 - acc: 0.8360\n",
            "Epoch 852/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4074 - acc: 0.8335\n",
            "Epoch 853/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4110 - acc: 0.8351\n",
            "Epoch 854/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4076 - acc: 0.8342\n",
            "Epoch 855/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4055 - acc: 0.8334\n",
            "Epoch 856/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4067 - acc: 0.8347\n",
            "Epoch 857/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4077 - acc: 0.8343\n",
            "Epoch 858/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4099 - acc: 0.8359\n",
            "Epoch 859/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4083 - acc: 0.8353\n",
            "Epoch 860/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4060 - acc: 0.8349\n",
            "Epoch 861/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4081 - acc: 0.8355\n",
            "Epoch 862/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4086 - acc: 0.8342\n",
            "Epoch 863/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4056 - acc: 0.8361\n",
            "Epoch 864/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4076 - acc: 0.8365\n",
            "Epoch 865/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4098 - acc: 0.8326\n",
            "Epoch 866/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4060 - acc: 0.8362\n",
            "Epoch 867/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4058 - acc: 0.8359\n",
            "Epoch 868/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4055 - acc: 0.8347\n",
            "Epoch 869/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4072 - acc: 0.8386\n",
            "Epoch 870/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4076 - acc: 0.8360\n",
            "Epoch 871/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4077 - acc: 0.8355\n",
            "Epoch 872/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4106 - acc: 0.8344\n",
            "Epoch 873/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4069 - acc: 0.8352\n",
            "Epoch 874/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4099 - acc: 0.8350\n",
            "Epoch 875/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4081 - acc: 0.8331\n",
            "Epoch 876/1000\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4071 - acc: 0.8339\n",
            "Epoch 877/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4083 - acc: 0.8348\n",
            "Epoch 878/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4078 - acc: 0.8355\n",
            "Epoch 879/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4058 - acc: 0.8360\n",
            "Epoch 880/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4048 - acc: 0.8366\n",
            "Epoch 881/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4076 - acc: 0.8341\n",
            "Epoch 882/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4100 - acc: 0.8350\n",
            "Epoch 883/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4082 - acc: 0.8360\n",
            "Epoch 884/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4077 - acc: 0.8354\n",
            "Epoch 885/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4085 - acc: 0.8329\n",
            "Epoch 886/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4088 - acc: 0.8346\n",
            "Epoch 887/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4084 - acc: 0.8352\n",
            "Epoch 888/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4075 - acc: 0.8373\n",
            "Epoch 889/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4097 - acc: 0.8351\n",
            "Epoch 890/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4081 - acc: 0.8359\n",
            "Epoch 891/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4116 - acc: 0.8349\n",
            "Epoch 892/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4052 - acc: 0.8361\n",
            "Epoch 893/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4088 - acc: 0.8321\n",
            "Epoch 894/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4085 - acc: 0.8346\n",
            "Epoch 895/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4067 - acc: 0.8340\n",
            "Epoch 896/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4058 - acc: 0.8356\n",
            "Epoch 897/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4075 - acc: 0.8374\n",
            "Epoch 898/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4067 - acc: 0.8355\n",
            "Epoch 899/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4066 - acc: 0.8366\n",
            "Epoch 900/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4105 - acc: 0.8364\n",
            "Epoch 901/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4094 - acc: 0.8345\n",
            "Epoch 902/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4072 - acc: 0.8346\n",
            "Epoch 903/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4063 - acc: 0.8372\n",
            "Epoch 904/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4077 - acc: 0.8361\n",
            "Epoch 905/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4076 - acc: 0.8351\n",
            "Epoch 906/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4064 - acc: 0.8357\n",
            "Epoch 907/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4063 - acc: 0.8350\n",
            "Epoch 908/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4072 - acc: 0.8347\n",
            "Epoch 909/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4091 - acc: 0.8330\n",
            "Epoch 910/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4083 - acc: 0.8334\n",
            "Epoch 911/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4072 - acc: 0.8356\n",
            "Epoch 912/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4065 - acc: 0.8374\n",
            "Epoch 913/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4110 - acc: 0.8359\n",
            "Epoch 914/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4063 - acc: 0.8354\n",
            "Epoch 915/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4096 - acc: 0.8345\n",
            "Epoch 916/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4058 - acc: 0.8345\n",
            "Epoch 917/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4096 - acc: 0.8364\n",
            "Epoch 918/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4085 - acc: 0.8356\n",
            "Epoch 919/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4090 - acc: 0.8364\n",
            "Epoch 920/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4083 - acc: 0.8360\n",
            "Epoch 921/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4086 - acc: 0.8342\n",
            "Epoch 922/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4061 - acc: 0.8359\n",
            "Epoch 923/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4071 - acc: 0.8340\n",
            "Epoch 924/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4093 - acc: 0.8325\n",
            "Epoch 925/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4074 - acc: 0.8351\n",
            "Epoch 926/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4061 - acc: 0.8360\n",
            "Epoch 927/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4070 - acc: 0.8340\n",
            "Epoch 928/1000\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4088 - acc: 0.8376\n",
            "Epoch 929/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4086 - acc: 0.8330\n",
            "Epoch 930/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4071 - acc: 0.8364\n",
            "Epoch 931/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4078 - acc: 0.8346\n",
            "Epoch 932/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4052 - acc: 0.8373\n",
            "Epoch 933/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4076 - acc: 0.8367\n",
            "Epoch 934/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4057 - acc: 0.8359\n",
            "Epoch 935/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4073 - acc: 0.8320\n",
            "Epoch 936/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4080 - acc: 0.8349\n",
            "Epoch 937/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4077 - acc: 0.8360\n",
            "Epoch 938/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4091 - acc: 0.8328\n",
            "Epoch 939/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4086 - acc: 0.8371\n",
            "Epoch 940/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4067 - acc: 0.8351\n",
            "Epoch 941/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4084 - acc: 0.8313\n",
            "Epoch 942/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4088 - acc: 0.8348\n",
            "Epoch 943/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4085 - acc: 0.8360\n",
            "Epoch 944/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4109 - acc: 0.8319\n",
            "Epoch 945/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4071 - acc: 0.8346\n",
            "Epoch 946/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4066 - acc: 0.8369\n",
            "Epoch 947/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4058 - acc: 0.8366\n",
            "Epoch 948/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4073 - acc: 0.8349\n",
            "Epoch 949/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4069 - acc: 0.8355\n",
            "Epoch 950/1000\n",
            "8000/8000 [==============================] - 0s 38us/step - loss: 0.4089 - acc: 0.8332\n",
            "Epoch 951/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4074 - acc: 0.8340\n",
            "Epoch 952/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4059 - acc: 0.8356\n",
            "Epoch 953/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4062 - acc: 0.8362\n",
            "Epoch 954/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4059 - acc: 0.8344\n",
            "Epoch 955/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4071 - acc: 0.8361\n",
            "Epoch 956/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4078 - acc: 0.8340\n",
            "Epoch 957/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4078 - acc: 0.8324\n",
            "Epoch 958/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4060 - acc: 0.8365\n",
            "Epoch 959/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4060 - acc: 0.8349\n",
            "Epoch 960/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4087 - acc: 0.8356\n",
            "Epoch 961/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4079 - acc: 0.8357\n",
            "Epoch 962/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4073 - acc: 0.8340\n",
            "Epoch 963/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4085 - acc: 0.8349\n",
            "Epoch 964/1000\n",
            "8000/8000 [==============================] - 0s 29us/step - loss: 0.4098 - acc: 0.8329\n",
            "Epoch 965/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4065 - acc: 0.8349\n",
            "Epoch 966/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4083 - acc: 0.8367\n",
            "Epoch 967/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4070 - acc: 0.8346\n",
            "Epoch 968/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4056 - acc: 0.8359\n",
            "Epoch 969/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4085 - acc: 0.8373\n",
            "Epoch 970/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4065 - acc: 0.8340\n",
            "Epoch 971/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4041 - acc: 0.8352\n",
            "Epoch 972/1000\n",
            "8000/8000 [==============================] - 0s 31us/step - loss: 0.4066 - acc: 0.8358\n",
            "Epoch 973/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4074 - acc: 0.8337\n",
            "Epoch 974/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4078 - acc: 0.8336\n",
            "Epoch 975/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4068 - acc: 0.8352\n",
            "Epoch 976/1000\n",
            "8000/8000 [==============================] - 0s 43us/step - loss: 0.4066 - acc: 0.8370\n",
            "Epoch 977/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4085 - acc: 0.8325\n",
            "Epoch 978/1000\n",
            "8000/8000 [==============================] - 0s 30us/step - loss: 0.4074 - acc: 0.8339\n",
            "Epoch 979/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4071 - acc: 0.8364\n",
            "Epoch 980/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4073 - acc: 0.8350\n",
            "Epoch 981/1000\n",
            "8000/8000 [==============================] - 0s 43us/step - loss: 0.4066 - acc: 0.8330\n",
            "Epoch 982/1000\n",
            "8000/8000 [==============================] - 0s 40us/step - loss: 0.4082 - acc: 0.8352\n",
            "Epoch 983/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4065 - acc: 0.8352\n",
            "Epoch 984/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4055 - acc: 0.8339\n",
            "Epoch 985/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4065 - acc: 0.8345\n",
            "Epoch 986/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4076 - acc: 0.8359\n",
            "Epoch 987/1000\n",
            "8000/8000 [==============================] - 0s 43us/step - loss: 0.4065 - acc: 0.8360\n",
            "Epoch 988/1000\n",
            "8000/8000 [==============================] - 0s 37us/step - loss: 0.4064 - acc: 0.8382\n",
            "Epoch 989/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4098 - acc: 0.8346\n",
            "Epoch 990/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4084 - acc: 0.8362\n",
            "Epoch 991/1000\n",
            "8000/8000 [==============================] - 0s 41us/step - loss: 0.4059 - acc: 0.8361\n",
            "Epoch 992/1000\n",
            "8000/8000 [==============================] - 0s 36us/step - loss: 0.4080 - acc: 0.8365\n",
            "Epoch 993/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4069 - acc: 0.8351\n",
            "Epoch 994/1000\n",
            "8000/8000 [==============================] - 0s 34us/step - loss: 0.4063 - acc: 0.8359\n",
            "Epoch 995/1000\n",
            "8000/8000 [==============================] - 0s 32us/step - loss: 0.4062 - acc: 0.8367\n",
            "Epoch 996/1000\n",
            "8000/8000 [==============================] - 0s 33us/step - loss: 0.4059 - acc: 0.8355\n",
            "Epoch 997/1000\n",
            "8000/8000 [==============================] - 0s 35us/step - loss: 0.4062 - acc: 0.8352\n",
            "Epoch 998/1000\n",
            "8000/8000 [==============================] - 0s 44us/step - loss: 0.4053 - acc: 0.8339\n",
            "Epoch 999/1000\n",
            "8000/8000 [==============================] - 0s 42us/step - loss: 0.4058 - acc: 0.8361\n",
            "Epoch 1000/1000\n",
            "8000/8000 [==============================] - 0s 39us/step - loss: 0.4035 - acc: 0.8335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f556a8adef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1qamx3nGRac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_prediction = classifier.predict(test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWt2Rf2iKWF5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e5dbe076-52a9-4634-cf4e-bbf6579cfc7d"
      },
      "source": [
        "classifier.predict_classes(test_x)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       ...,\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izOIIrewKiFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLDSlW30KnOW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2d7bcebb-fd0b-41b8-9c4d-2c985f8b131e"
      },
      "source": [
        "confusion_matrix(test_y, classifier.predict_classes(test_x))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1552,   43],\n",
              "       [ 274,  131]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56YZ6oc_K6mC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32a7fc6b-c824-4451-8dde-c0e3af4d5431"
      },
      "source": [
        "accuracy_score(test_y, classifier.predict_classes(test_x))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8415"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30bl3WxUMfId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}